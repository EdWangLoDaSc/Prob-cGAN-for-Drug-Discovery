{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdWangLoDaSc/Prob-cGAN-for-Drug-Discovery/blob/main/Kriging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwm99IJ3icJG"
      },
      "outputs": [],
      "source": [
        "pip install pykrige"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jo5kgwo7uF9A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from scipy.interpolate import griddata\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Cropping2D,\n",
        "    AveragePooling2D, Flatten, Reshape, Dropout, Conv2D, LSTM,\n",
        "    RepeatVector\n",
        ")\n",
        "from tensorflow.keras.losses import MSE\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "import h5py\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from pykrige.ok3d import OrdinaryKriging3D\n",
        "from pykrige.uk3d import UniversalKriging3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiDC3zr63Qvo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXWYBJVIuF9F"
      },
      "source": [
        "# 3D kriging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "from tqdm import tqdm\n",
        "\n",
        "def generate_data(f,n, sen_num_kind_list, sen_num_var_list):\n",
        "    lat = np.array(f['lat'])\n",
        "    lon = np.array(f['lon'])\n",
        "    sst = np.array(f['sst'])\n",
        "    sst1 = np.nan_to_num(sst)\n",
        "    sst_reshape = sst[0, :].reshape(len(lat[0, :]), len(lon[0, :]), order='F')\n",
        "    xv1, yv1 = np.meshgrid(lon[0, :], lat[0, :])\n",
        "\n",
        "    # Adjust X_ki to have 3 columns instead of 2 to include times\n",
        "    X_ki = np.zeros((1040 * n, 3))\n",
        "    y_ki = np.zeros((1040 * n, 1))\n",
        "\n",
        "    for ki in tqdm(range(len(sen_num_kind_list))):\n",
        "        sen_num = sen_num_kind_list[ki]\n",
        "        # Also adjust X_va to have 3 columns\n",
        "        X_va = np.zeros((1040 * n, 3))\n",
        "        y_va = np.zeros((1040 * n, 1))\n",
        "\n",
        "        for va in tqdm(range(len(sen_num_var_list))):\n",
        "            X_t = np.zeros((1040, len(lat[0, :]), len(lon[0, :]), 2))\n",
        "            y_t = np.zeros((1040, len(lat[0, :]), len(lon[0, :]), 1))\n",
        "            times = 0\n",
        "            for t in tqdm(range(1040)):\n",
        "                y_t[t, :, :, 0] = np.nan_to_num(sst[t, :].reshape(len(lat[0, :]), len(lon[0, :]), order='F'))\n",
        "\n",
        "                np.random.seed(sen_num_var_list[va])\n",
        "                sparse_locations_lat = np.random.randint(len(lat[0, :]), size=(sen_num))\n",
        "                sparse_locations_lon = np.random.randint(len(lon[0, :]), size=(sen_num))\n",
        "\n",
        "                sparse_locations = np.column_stack((sparse_locations_lat, sparse_locations_lon))\n",
        "                times += 0.00001\n",
        "                for s in range(sen_num):\n",
        "                    a, b = sparse_locations[s]\n",
        "                    while np.isnan(sst_reshape[int(a), int(b)]):\n",
        "                        a = np.random.randint(len(lat[0, :]))\n",
        "                        b = np.random.randint(len(lon[0, :]))\n",
        "                        sparse_locations[s, 0] = a\n",
        "                        sparse_locations[s, 1] = b\n",
        "\n",
        "                sparse_data = np.zeros((sen_num))\n",
        "                for s in range(sen_num):\n",
        "                    sparse_data[s] = (y_t[t, :, :, 0][int(sparse_locations[s, 0]), int(sparse_locations[s, 1])])\n",
        "\n",
        "                # Incorporate times into X_va along with the locations\n",
        "                X_va[n * t:n * (t + 1), :2] = sparse_locations\n",
        "                X_va[n * t:n * (t + 1), 2] = times\n",
        "                y_va[n * t:n * (t + 1), :] = sparse_data.reshape((n, 1))\n",
        "\n",
        "            X_ki[1040 * n * ki:1040 * n * (ki + 1), :] = X_va\n",
        "            y_ki[1040 * n * ki:1040 * n * (ki + 1), :] = y_va\n",
        "\n",
        "    return X_ki, y_ki\n",
        "\n",
        "\n",
        "f = h5py.File('/content/drive/MyDrive/Physics/Physics/sst_weekly.mat', 'r')\n",
        "\n",
        "n = 340\n",
        "sen_num_kind_list = [n]\n",
        "sen_num_var_list = [900]\n",
        "X_ki, y_ki = generate_data(f, n,sen_num_kind_list, sen_num_var_list)\n"
      ],
      "metadata": {
        "id": "CVhrZCskzzgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "# Assuming you have a working OrdinaryKriging3D implementation available\n",
        "\n",
        "# Load y_test\n",
        "y_test = np.load('/content/drive/MyDrive/Physics/Dataset10/y_NOAA_test.npy', mmap_mode='r')\n",
        "\n",
        "# Prepare grid for Kriging interpolation\n",
        "gridx = np.arange(0.0, 180, 1)\n",
        "gridy = np.arange(0.0, 360, 1)\n",
        "gridz = np.arange(0.0, 0.00006, 0.00001)\n",
        "\n",
        "# Initialize metrics\n",
        "ssim_vals = []\n",
        "psnr_vals = []\n",
        "x_time = X_ki[0:3*n][:, 2]\n",
        "\n",
        "times = 0\n",
        "for i in range(0, 30):\n",
        "    # Reshape and select subsets for Kriging\n",
        "    X_va_2 = X_ki[i*n:(i+3)*n]\n",
        "    y_va_2 = y_ki[i*n:(i+3)*n]\n",
        "\n",
        "    # Perform 3D Kriging\n",
        "    ok3d_2 = OrdinaryKriging3D(\n",
        "        X_va_2[:, 0], X_va_2[:, 1], x_time, y_va_2,\n",
        "        variogram_model=\"spherical\", nlags=8\n",
        "    )\n",
        "    start_time = time.time()\n",
        "    k3d1, ss3d = ok3d_2.execute(\"grid\", gridx, gridy, gridz)\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(f\"Inference Time for i={i}: \", end_time - start_time, \"seconds\")\n",
        "    times+=(end_time - start_time)\n",
        "    # Apply mask and rotate\n",
        "    first_element = y_test[0, :, :, :1]\n",
        "    mask = (first_element == 0)\n",
        "    result = np.empty_like(k3d1)\n",
        "    for j in range(k3d1.shape[0]):\n",
        "        masked_rotated_element = np.where(mask.squeeze(), 0, first_element[:, :, 0])\n",
        "        masked_rotated_element = np.rot90(masked_rotated_element, k=1)\n",
        "        result[j] = k3d1[j] + masked_rotated_element\n",
        "\n",
        "    # Compare to true images and calculate metrics\n",
        "    true_set = [np.rot90(y_test[i+j, :, :, :1], k=1) for j in range(3, 6)]\n",
        "    result_set = result[-3:]  # Last 3 images as they correspond to the true_set\n",
        "\n",
        "    for true, pred in zip(true_set, result_set):\n",
        "        ssim_vals.append(ssim(true.squeeze(), pred, data_range=pred.max() - pred.min()))\n",
        "        psnr_vals.append(psnr(true.squeeze(), pred, data_range=pred.max() - pred.min()))\n",
        "\n",
        "# After the loop\n",
        "# Calculate average metrics or otherwise summarize them\n",
        "avg_ssim = np.mean(ssim_vals)\n",
        "avg_psnr = np.mean(psnr_vals)\n",
        "\n",
        "print(f\"Average SSIM: {avg_ssim}\")\n",
        "print(f\"Average PSNR: {avg_psnr}\")\n"
      ],
      "metadata": {
        "id": "M9-f8XGcqDVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzeJfMREuF9I"
      },
      "source": [
        "# 2D kriging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "from tqdm import tqdm\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "def generate_data(f,n, sen_num_kind_list, sen_num_var_list):\n",
        "    lat = np.array(f['lat'])\n",
        "    lon = np.array(f['lon'])\n",
        "    sst = np.array(f['sst'])\n",
        "    sst1 = np.nan_to_num(sst)\n",
        "    sst_reshape = sst[0, :].reshape(len(lat[0, :]), len(lon[0, :]), order='F')\n",
        "    xv1, yv1 = np.meshgrid(lon[0, :], lat[0, :])\n",
        "\n",
        "    X_ki = np.zeros((1040 * n, 2))\n",
        "    y_ki = np.zeros((1040 * n, 1))\n",
        "\n",
        "    for ki in tqdm(range(len(sen_num_kind_list))):\n",
        "        sen_num = sen_num_kind_list[ki]\n",
        "        X_va = np.zeros((1040 * n, 2))\n",
        "        y_va = np.zeros((1040 * n, 1))\n",
        "\n",
        "        for va in tqdm(range(len(sen_num_var_list))):\n",
        "            X_t = np.zeros((1040, len(lat[0, :]), len(lon[0, :]), 2))\n",
        "            y_t = np.zeros((1040, len(lat[0, :]), len(lon[0, :]), 1))\n",
        "\n",
        "            for t in tqdm(range(1040)):\n",
        "                y_t[t, :, :, 0] = np.nan_to_num(sst[t, :].reshape(len(lat[0, :]), len(lon[0, :]), order='F'))\n",
        "\n",
        "                np.random.seed(sen_num_var_list[va])\n",
        "                sparse_locations_lat = np.random.randint(len(lat[0, :]), size=(sen_num))\n",
        "                sparse_locations_lon = np.random.randint(len(lon[0, :]), size=(sen_num))\n",
        "\n",
        "                sparse_locations = np.column_stack((sparse_locations_lat, sparse_locations_lon))\n",
        "\n",
        "                for s in range(sen_num):\n",
        "                    a, b = sparse_locations[s]\n",
        "                    while np.isnan(sst_reshape[int(a), int(b)]):\n",
        "                        a = np.random.randint(len(lat[0, :]))\n",
        "                        b = np.random.randint(len(lon[0, :]))\n",
        "                        sparse_locations[s, 0] = a\n",
        "                        sparse_locations[s, 1] = b\n",
        "\n",
        "                sparse_data = np.zeros((sen_num))\n",
        "                for s in range(sen_num):\n",
        "                    sparse_data[s] = (y_t[t, :, :, 0][int(sparse_locations[s, 0]), int(sparse_locations[s, 1])])\n",
        "\n",
        "                X_va[n * t:n * (t + 1), :] = sparse_locations\n",
        "                y_va[n * t:n * (t + 1), :] = sparse_data.reshape((n, 1))\n",
        "\n",
        "            X_ki[1040 * n * ki:1040 * n * (ki + 1), :] = X_va\n",
        "            y_ki[1040 * n * ki:1040 * n * (ki + 1), :] = y_va\n",
        "\n",
        "    return X_ki, y_ki\n",
        "\n",
        "\n",
        "f = h5py.File('/content/drive/MyDrive/Physics/Physics/sst_weekly.mat', 'r')\n",
        "n=320\n",
        "\n",
        "sen_num_kind_list = [n]\n",
        "sen_num_var_list = [900]\n",
        "X_ki, y_ki = generate_data(f,n ,sen_num_kind_list, sen_num_var_list)\n"
      ],
      "metadata": {
        "id": "5TEo5E4uQ7vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE-k3Zl-uF9I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pykrige.ok import OrdinaryKriging\n",
        "\n",
        "def kriging_interpolation(x, y, gridx, gridy):\n",
        "    \"\"\"\n",
        "    Performs Ordinary Kriging interpolation.\n",
        "\n",
        "    Args:\n",
        "        x (ndarray): Input x coordinates array.\n",
        "        y (ndarray): Input y coordinates array.\n",
        "        n (int): Number of points to select.\n",
        "        gridx (ndarray): X direction grid points.\n",
        "        gridy (ndarray): Y direction grid points.\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Interpolated values.\n",
        "    \"\"\"\n",
        "\n",
        "    OK = OrdinaryKriging(\n",
        "        x[:, 0],\n",
        "        x[:, 1],\n",
        "        y,\n",
        "        variogram_model='spherical',\n",
        "        verbose=True,\n",
        "        enable_plotting=True,\n",
        "    )\n",
        "\n",
        "    zstar, ss = OK.execute(\"grid\", gridx, gridy)\n",
        "\n",
        "    cax = plt.imshow(zstar, extent=(0, 180, 0, 360))\n",
        "    cbar = plt.colorbar(cax)\n",
        "    plt.scatter(x[:, 0], x[:, 1], c='k', marker='.')\n",
        "    plt.title(f'{n}_Porosity estimate')\n",
        "    plt.show()\n",
        "\n",
        "    return zstar\n",
        "i = 6\n",
        "k = 3*i\n",
        "# Sample usage\n",
        "img_num_0 = k\n",
        "img_num_1 = k + 1\n",
        "img_num_2 = k + 2\n",
        "img_num_3 = k + 3\n",
        "img_num_4 = k + 4\n",
        "img_num_5 = k + 5\n",
        "\n",
        "gridx = np.arange(0, 180, 1, dtype='float64')\n",
        "gridy = np.arange(0, 360, 1, dtype='float64')\n",
        "X_va = X_ki.reshape((1040, 200, 2))\n",
        "y_va = y_ki.reshape((1040, 200, 1))\n",
        "zstar_0 = kriging_interpolation(X_va[img_num_0], y_va[img_num_0],  gridx, gridy)\n",
        "zstar_1 = kriging_interpolation(X_va[img_num_1], y_va[img_num_1],  gridx, gridy)\n",
        "zstar_2 = kriging_interpolation(X_va[img_num_2], y_va[img_num_2],  gridx, gridy)\n",
        "zstar_3 = kriging_interpolation(X_va[img_num_3], y_va[img_num_3],  gridx, gridy)\n",
        "zstar_4 = kriging_interpolation(X_va[img_num_4], y_va[img_num_4], gridx, gridy)\n",
        "zstar_5 = kriging_interpolation(X_va[img_num_5], y_va[img_num_5],  gridx, gridy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_va = X_ki.reshape((1040, n, 2))\n",
        "y_va = y_ki.reshape((1040, n, 1))\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pykrige.ok import OrdinaryKriging\n",
        "\n",
        "def kriging_interpolation(x, y, gridx, gridy):\n",
        "    \"\"\"\n",
        "    Performs Ordinary Kriging interpolation.\n",
        "\n",
        "    Args:\n",
        "        x (ndarray): Input x coordinates array.\n",
        "        y (ndarray): Input y coordinates array.\n",
        "        n (int): Number of points to select.\n",
        "        gridx (ndarray): X direction grid points.\n",
        "        gridy (ndarray): Y direction grid points.\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Interpolated values.\n",
        "    \"\"\"\n",
        "\n",
        "    variogram_model = 'spherical'\n",
        "    '''variogram_parameters = {'sill': 0.1, 'range': 50 , 'nugget': 0.1}  # Example parameters'''\n",
        "\n",
        "    OK = OrdinaryKriging(\n",
        "        x[:, 0],\n",
        "        x[:, 1],\n",
        "        y,\n",
        "        variogram_model=variogram_model,\n",
        "        verbose=True,\n",
        "        enable_plotting=False,  # Set to False to avoid automatic plotting\n",
        "        nlags=8\n",
        "    )\n",
        "\n",
        "    zstar, ss = OK.execute(\"grid\", gridx, gridy)\n",
        "\n",
        "    cax = plt.imshow(zstar, extent=(0, 180, 0, 360))\n",
        "    cbar = plt.colorbar(cax)\n",
        "    plt.scatter(x[:, 0], x[:, 1], c='k', marker='.')\n",
        "    plt.title(f'{n}_Porosity estimate')\n",
        "    plt.show()\n",
        "\n",
        "    return zstar\n",
        "\n",
        "\n",
        "y_test = np.load('/content/drive/MyDrive/Physics/Dataset10/y_NOAA_test.npy',mmap_mode = 'r')\n",
        "# Extract the first element of x_train\n",
        "first_element = y_test[0][:,:,:1]\n",
        "\n",
        "# Create a mask for zero values\n",
        "mask = (first_element == 0)\n",
        "\n",
        "rotated_element = np.rot90(first_element, k=1)"
      ],
      "metadata": {
        "id": "qoFCQqHIwtkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "true_set = []\n",
        "predict_set = []\n",
        "import time\n",
        "total_time = 0\n",
        "for i in range(0, 5):\n",
        "    k = 3 * i\n",
        "    print(i)\n",
        "    # Sample usage\n",
        "    img_num_0 = k\n",
        "    img_num_1 = k + 1\n",
        "    img_num_2 = k + 2\n",
        "    img_num_3 = k + 3\n",
        "\n",
        "    gridx = np.arange(0, 180, 1, dtype='float64')\n",
        "    gridy = np.arange(0, 360, 1, dtype='float64')\n",
        "    X_va = X_ki.reshape((1040, n, 2))\n",
        "    y_va = y_ki.reshape((1040, n, 1))\n",
        "    zstar_0 = kriging_interpolation(X_va[img_num_0], y_va[img_num_0],  gridx, gridy)\n",
        "    zstar_1 = kriging_interpolation(X_va[img_num_1], y_va[img_num_1],  gridx, gridy)\n",
        "    zstar_2 = kriging_interpolation(X_va[img_num_2], y_va[img_num_2],  gridx, gridy)\n",
        "    zstar_3 = kriging_interpolation(X_va[img_num_3], y_va[img_num_3],  gridx, gridy)\n",
        "\n",
        "    # Flatten images into 1D vectors\n",
        "    X = np.array([zstar_0.flatten(), zstar_1.flatten(), zstar_2.flatten()]).T\n",
        "\n",
        "    # Target value is the next image zstar_3\n",
        "    y = zstar_3.flatten()\n",
        "\n",
        "    # Create linear regression model\n",
        "    model = LinearRegression()\n",
        "\n",
        "    # Fit the model\n",
        "    model.fit(X, y)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Perform prediction for the next three steps\n",
        "    next_image_1 = model.predict(np.array([zstar_0.flatten(), zstar_1.flatten(), zstar_2.flatten()]).T)\n",
        "    next_image_2 = model.predict(np.array([zstar_1.flatten(), zstar_2.flatten(), next_image_1]).T)\n",
        "    next_image_3 = model.predict(np.array([zstar_2.flatten(), next_image_1, next_image_2]).T)\n",
        "\n",
        "    rotated_element = np.rot90(first_element, k=1).reshape(360, 180, 1)\n",
        "    next_image_1 = next_image_1.reshape(360, 180, 1)\n",
        "    next_image_2 = next_image_2.reshape(360, 180, 1)\n",
        "    next_image_3 = next_image_3.reshape(360, 180, 1)\n",
        "\n",
        "    # Add the rotated element to next_image_1, next_image_2, and next_image_3\n",
        "    next_image_1 += rotated_element\n",
        "    next_image_2 += rotated_element\n",
        "    next_image_3 += rotated_element\n",
        "\n",
        "    # End time for the current iteration\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate the time taken for the current iteration\n",
        "    iteration_time = end_time - start_time\n",
        "    print(\"Total time taken: \", iteration_time, \"minutes\")\n",
        "    # Accumulate the time for all iterations\n",
        "    total_time += iteration_time\n",
        "\n",
        "    # Append to true_set and predict_set\n",
        "    true_pic_1 = y_test[k + 3]\n",
        "    true_pic_2 = y_test[k + 4]\n",
        "    true_pic_3 = y_test[k + 5]\n",
        "\n",
        "    # Rotate true_pic_1 by 90 degrees clockwise\n",
        "    rotated_true_pic_1 = np.rot90(true_pic_1, k=1)\n",
        "\n",
        "    # Rotate true_pic_2 by 90 degrees clockwise\n",
        "    rotated_true_pic_2 = np.rot90(true_pic_2, k=1)\n",
        "\n",
        "    # Rotate true_pic_3 by 90 degrees clockwise\n",
        "    rotated_true_pic_3 = np.rot90(true_pic_3, k=1)\n",
        "\n",
        "    true_set.append([rotated_true_pic_1, rotated_true_pic_2, rotated_true_pic_3])\n",
        "    predict_set.append([next_image_1, next_image_2, next_image_3])\n",
        "\n",
        "true_set = np.array(true_set)\n",
        "predict_set = np.array(predict_set)\n"
      ],
      "metadata": {
        "id": "hdE6rwwtf_s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_time_minutes = total_time / 60  # Convert total_time to minutes\n",
        "print(\"Total time taken for all iterations: \", total_time_minutes, \"minutes\")\n",
        "\n",
        "\n",
        "\n",
        "1040/30*total_time_minutes*60"
      ],
      "metadata": {
        "id": "ukgpgyuyzOQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_set.shape"
      ],
      "metadata": {
        "id": "il0MhfgK7Qlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_set = predict_set.reshape((15,360,180,1))\n",
        "true_set = true_set.reshape((15,360,180,1))"
      ],
      "metadata": {
        "id": "EQWlNWrloVc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(predict_set[10,:,:,:])"
      ],
      "metadata": {
        "id": "osqlbjiog5sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "# Calculate SSIM and PSNR for the first predicted image\n",
        "ssim_1 = ssim(true_set, predict_set, multichannel=True)\n",
        "# Calculate PSNR for the first predicted image\n",
        "psnr_1 = psnr(true_set, predict_set, data_range=predict_set.max() - predict_set.min())\n",
        "\n",
        "# Calculate SSIM and PSNR for the second predicted imag\n",
        "ssim_1"
      ],
      "metadata": {
        "id": "bZbR5BFxS5f4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "cell_execution_strategy": "setup",
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}